{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #for graph plotting\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename)) \n#import necessary machine learning library\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-03T14:50:35.176525Z","iopub.execute_input":"2023-11-03T14:50:35.176861Z","iopub.status.idle":"2023-11-03T14:50:35.196766Z","shell.execute_reply.started":"2023-11-03T14:50:35.176837Z","shell.execute_reply":"2023-11-03T14:50:35.195765Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"/kaggle/input/nba-data/Advanced.csv\n/kaggle/input/nba-data/Player Season Info.csv\n/kaggle/input/nba-data/Player Career Info.csv\n/kaggle/input/nba-data/Player Shooting.csv\n/kaggle/input/nba-data/Opponent Stats Per Game.csv\n/kaggle/input/nba-data/Player Totals.csv\n/kaggle/input/nba-data/Opponent Stats Per 100 Poss.csv\n/kaggle/input/nba-data/Per 100 Poss.csv\n/kaggle/input/nba-data/Team Summaries.csv\n/kaggle/input/nba-data/Player Per Game.csv\n/kaggle/input/nba-data/All-Star Selections.csv\n/kaggle/input/nba-data/End of Season Teams (Voting).csv\n/kaggle/input/nba-data/Player Play By Play.csv\n/kaggle/input/nba-data/End of Season Teams.csv\n/kaggle/input/nba-data/Team Stats Per 100 Poss.csv\n/kaggle/input/nba-data/Per 36 Minutes.csv\n/kaggle/input/nba-data/Opponent Totals.csv\n/kaggle/input/nba-data/Team Abbrev.csv\n/kaggle/input/nba-data/Player Award Shares.csv\n/kaggle/input/nba-data/Team Totals.csv\n/kaggle/input/nba-data/Team Stats Per Game.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**3-point evolution in NBA using data from history**","metadata":{}},{"cell_type":"markdown","source":"NBA history data from https://www.kaggle.com/code/benbcoleman/2023-nba-all-star-predictions?kernelSessionId=116885548","metadata":{}},{"cell_type":"code","source":"player_shooting = pd.read_csv(\"/kaggle/input/nba-data/Player Shooting.csv\")\nfeatures = ['avg_dist_fga', 'percent_fga_from_x2p_range', 'percent_fga_from_x0_3_range',\n       'percent_fga_from_x3_10_range', 'percent_fga_from_x10_16_range',\n       'percent_fga_from_x16_3p_range', 'percent_fga_from_x3p_range']\n#create target_variable\nsuccess_thres = 0.5 # 50% above is considered good percentage shot in NBA\ntarget_variable = 'shot_successful'\nplayer_shooting[target_variable] = (player_shooting['fg_percent'] >= success_thres).astype(int) # return 0 or 1 \ndf_subset = player_shooting[features + [target_variable]]\nndf = df_subset.dropna()\nX = ndf.drop([\"shot_successful\"], axis = 1)\ny = ndf[\"shot_successful\"]","metadata":{"execution":{"iopub.status.busy":"2023-11-03T14:50:35.198170Z","iopub.execute_input":"2023-11-03T14:50:35.199124Z","iopub.status.idle":"2023-11-03T14:50:35.260823Z","shell.execute_reply.started":"2023-11-03T14:50:35.199088Z","shell.execute_reply":"2023-11-03T14:50:35.259461Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"Exploratory Data Analysis (EDA):\n\nBegin with EDA to understand the trends in three-point shooting. Explore the following aspects:\nHistorical three-point shooting percentages.\nThe distribution of three-point attempts and makes.\nPlayer and team records related to three-point shooting.\nTeam strategies in different eras.","metadata":{}},{"cell_type":"code","source":"# we won't use heaves shot because it is too far and it is for inhuman.\nX_train,X_test,y_train,y_test = train_test_split(X, y , test_size = .33, random_state = 42)\nmodel = LogisticRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model's performance\naccuracy = accuracy_score(y_test, y_pred)\nconfusion = confusion_matrix(y_test, y_pred)\n#classification_report = classification_report(y_test, y_pred)\n\n# Print the evaluation results\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", confusion)\n#print(\"Classification Report:\\n\", classification_report)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T14:50:35.262835Z","iopub.execute_input":"2023-11-03T14:50:35.263172Z","iopub.status.idle":"2023-11-03T14:50:35.347338Z","shell.execute_reply.started":"2023-11-03T14:50:35.263145Z","shell.execute_reply":"2023-11-03T14:50:35.346520Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"Accuracy: 0.8513162773451983\nConfusion Matrix:\n [[4153  211]\n [ 591  439]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# randomforest classifier : less accurate than logistic regression","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n# we won't use heaves shot because it is too far and it is for inhuman.\nX_train,X_test,y_train,y_test = train_test_split(X, y , test_size = .33, random_state = 42)\nnmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nnmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = nmodel.predict(X_test)\n\n# Evaluate the model's performance\naccuracy = accuracy_score(y_test, y_pred)\nconfusion = confusion_matrix(y_test, y_pred)\n#classification_report = classification_report(y_test, y_pred)\n\n# Print the evaluation results\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", confusion)\n#print(\"Classification Report:\\n\", classification_report)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T14:50:35.350910Z","iopub.execute_input":"2023-11-03T14:50:35.351703Z","iopub.status.idle":"2023-11-03T14:50:37.505805Z","shell.execute_reply.started":"2023-11-03T14:50:35.351669Z","shell.execute_reply":"2023-11-03T14:50:37.504798Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"Accuracy: 0.8455691509084168\nConfusion Matrix:\n [[4075  289]\n [ 544  486]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Decision Tree model : less accurate than rainforest and logistic regression","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\n# we won't use heaves shot because it is too far and it is for inhuman.\nX_train,X_test,y_train,y_test = train_test_split(X, y , test_size = .33, random_state = 42)\nxmodel = DecisionTreeClassifier(random_state=42)\nxmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = xmodel.predict(X_test)\n\n# Evaluate the model's performance\naccuracy = accuracy_score(y_test, y_pred)\nconfusion = confusion_matrix(y_test, y_pred)\n#classification_report = classification_report(y_test, y_pred)\n\n# Print the evaluation results\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", confusion)\n#print(\"Classification Report:\\n\", classification_report)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T14:50:37.509895Z","iopub.execute_input":"2023-11-03T14:50:37.510309Z","iopub.status.idle":"2023-11-03T14:50:37.628540Z","shell.execute_reply.started":"2023-11-03T14:50:37.510280Z","shell.execute_reply":"2023-11-03T14:50:37.627468Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Accuracy: 0.7842046718576196\nConfusion Matrix:\n [[3731  633]\n [ 531  499]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# SVC has more accuracy than logistic regression","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\n# we won't use heaves shot because it is too far and it is for inhuman.\nX_train,X_test,y_train,y_test = train_test_split(X, y , test_size = .33, random_state = 42)\nymodel = SVC(kernel='linear', random_state=42)\n\nymodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = ymodel.predict(X_test)\n\n# Evaluate the model's performance\naccuracy = accuracy_score(y_test, y_pred)\nconfusion = confusion_matrix(y_test, y_pred)\n#classification_report = classification_report(y_test, y_pred)\n\n# Print the evaluation results\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", confusion)\n#print(\"Classification Report:\\n\", classification_report)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T14:50:37.629874Z","iopub.execute_input":"2023-11-03T14:50:37.630291Z","iopub.status.idle":"2023-11-03T14:50:41.298997Z","shell.execute_reply.started":"2023-11-03T14:50:37.630256Z","shell.execute_reply":"2023-11-03T14:50:41.297574Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"Accuracy: 0.8526140155728588\nConfusion Matrix:\n [[4171  193]\n [ 602  428]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# GradientBoostingClassifier has more accuracy than SVC","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n# we won't use heaves shot because it is too far and it is for inhuman.\nX_train,X_test,y_train,y_test = train_test_split(X, y , test_size = .33, random_state = 42)\nzmodel = GradientBoostingClassifier(n_estimators=100, random_state=42)\n\nzmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = zmodel.predict(X_test)\n\n# Evaluate the model's performance\naccuracy = accuracy_score(y_test, y_pred)\nconfusion = confusion_matrix(y_test, y_pred)\n#classification_report = classification_report(y_test, y_pred)\n\n# Print the evaluation results\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", confusion)\n#print(\"Classification Report:\\n\", classification_report)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T14:50:41.300545Z","iopub.execute_input":"2023-11-03T14:50:41.300923Z","iopub.status.idle":"2023-11-03T14:50:43.049613Z","shell.execute_reply.started":"2023-11-03T14:50:41.300889Z","shell.execute_reply":"2023-11-03T14:50:43.048528Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Accuracy: 0.853726362625139\nConfusion Matrix:\n [[4107  257]\n [ 532  498]]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n# we won't use heaves shot because it is too far and it is for inhuman.\nX_train,X_test,y_train,y_test = train_test_split(X, y , test_size = .33, random_state = 42)\nzmodel = GradientBoostingClassifier(n_estimators=100, random_state=42)\n\nzmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = zmodel.predict(X_test)\n\n# Evaluate the model's performance\naccuracy = accuracy_score(y_test, y_pred)\nconfusion = confusion_matrix(y_test, y_pred)\n#classification_report = classification_report(y_test, y_pred)\n\n# Print the evaluation results\nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", confusion)\n#print(\"Classification Report:\\n\", classification_report)","metadata":{"execution":{"iopub.status.busy":"2023-11-03T14:50:43.051250Z","iopub.execute_input":"2023-11-03T14:50:43.051613Z","iopub.status.idle":"2023-11-03T14:50:44.788975Z","shell.execute_reply.started":"2023-11-03T14:50:43.051584Z","shell.execute_reply":"2023-11-03T14:50:44.788047Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Accuracy: 0.853726362625139\nConfusion Matrix:\n [[4107  257]\n [ 532  498]]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"> So I founded the most accurate method for this project is GradientBoostingClassifier which has 85.3726362625139 accuracy. The model that we made can optimize shot selection, which can improve by getting more data such as the real coordinates of shooting, shot-clock left, defender's attribute, and etc. This project can improve to implement in real world for coach or nba players for more efficiency in their shooting. :)","metadata":{}}]}